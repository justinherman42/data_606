---
title: "project1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This project consists of 3 parts - two required and one bonus and is worth 15% of your grade.  The project is due at 11:59 PM on Sunday March 31.  I will accept late submissions with a penalty until the meetup after that when we review some projects.

Part A - ATM Forecast, ATM624Data.xlsx

 

In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable 'Cash' is provided in hundreds of dollars, other than that it is straight forward.   I am being somewhat ambiguous on purpose to make this have a little more business feeling.  Explain and demonstrate your process, techniques used and not used, and your actual forecast.  I am giving you data via an excel file, please provide your written report on your findings, visuals, discussion and your R code via an RPubs link along with the actual.rmd file  Also please submit the forecast which you will put in an Excel readable file.

 
# Load in ATM data 
+ Dataset consists of cash taken out of 4 different atms
+ We can see that each atm has exactly 365 transactions
+ I split the dataset by ATM machine, and graph the cash outflows in grid below
 
```{r,echo=FALSE, message=FALSE}
library(forecast)
library(readxl)
library(tidyverse)
library(car)
library(psych)
library(cowplot)
```

```{r}
## Load iN data
atm_data <- read_xlsx("ATM624Data.xlsx")
table(atm_data$ATM)


## scatterplot data  
ggplot(atm_data) + geom_point(aes(x=DATE, y=Cash))+
  facet_wrap(~ ATM,scales = "free")

## get mean 
atm_data %>% group_by(ATM) %>% 
  summarise(mean_avg=mean(Cash,na.rm=TRUE),
            median_avg= median(Cash,na.rm=TRUE)
            )


new_df <- split(atm_data, atm_data$ATM)




## Describe atm Datasets
lapply(new_df, function(x){
  describe(x[['Cash']])})
  
## graph timeplot
par(mfrow=c(2,2))
lapply(new_df,function(x){
  autoplot(ts(x[["Cash"]]))}
   )
## histograms
par(mfrow=c(2,2))
lapply(new_df,function(x){
  hist(x[["Cash"]],breaks=10)}
   )
names(new_df[2])
library(ggplot2)

# atm_data
# ggplot(as.data.frame(atm_data$ATM), aes(value)) + 
#     geom_histogram()# + 
#   #  facet_wrap(~ATM, scales = 'free_x')

    
#col_names_list <- c("ATM1","ATM2","ATM3","")
par(mfrow = c(2, 4))
for (col in 1:8) {
    hist(Glass[,col],main=col_names_list[col])
}    

df %>%
    spread(key = ATM, value = c("ATM1",""))


```


## CLoser look at ATM 1

```{r}
atm1 <- new_df$ATM1
atm1 <- atm1[,c("DATE","Cash")]
atm1 <- ts(atm1$cash,start=atm1$)
autoplot(atm1)
```


Part B - Forecasting Power, ResidentialCustomerForecastLoad-624.xlsx

 

Part B consists of a simple dataset of residential power usage for January 1998 until December 2013.  Your assignment is to model these data and a monthly forecast for 2014.  The data is given in a single file.  The variable 'KWH' is power consumption in Kilowatt hours, the rest is straight forward.    Add this to your existing files above. 

 

 

Part C - BONUS, optional (part or all), Waterflow_Pipe1.xlsx and Waterflow_Pipe2.xlsx

 

Part C consists of two data sets.  These are simple 2 columns sets, however they have different time stamps.  Your optional assignment is to time-base sequence the data and aggregate based on hour (example of what this looks like, follows).  Note for multiple recordings within an hour, take the mean.  Then to determine if the data is stationary and can it be forecast.  If so, provide a week forward forecast and present results via Rpubs and .rmd and the forecast in an Excel readable file.   

